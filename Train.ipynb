{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python notebook implements the training process of deep learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "%env SM_FRAMEWORK=tf.keras\n",
    "from segmentation_models.losses import *\n",
    "from segmentation_models.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VNet import vnet\n",
    "from UNet import unet_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "train_img_folder = 'Data/train_img'\n",
    "train_img_list = os.listdir(train_img_folder)\n",
    "for i in range(len(train_img_list)):\n",
    "    img = sitk.ReadImage(train_img_folder + '/' + train_img_list[i], imageIO=\"NrrdImageIO\")\n",
    "    curr_x = np.expand_dims(sitk.GetArrayFromImage(img), axis=0)\n",
    "    if i == 0:\n",
    "        x_train = curr_x\n",
    "    else:\n",
    "        x_train = np.concatenate((x_train, curr_x), axis=0)\n",
    "\n",
    "train_msk_folder = 'Data/train_msk'\n",
    "train_msk_list = os.listdir(train_msk_folder)\n",
    "for i in range(len(train_msk_list)):\n",
    "    seg = sitk.ReadImage(train_msk_folder + '/' + train_msk_list[i], imageIO=\"NrrdImageIO\")\n",
    "    curr_y = np.expand_dims(sitk.GetArrayFromImage(seg), axis=0)\n",
    "    if i == 0:\n",
    "        y_train = curr_y\n",
    "    else:\n",
    "        y_train = np.concatenate((y_train, curr_y), axis=0)\n",
    "    \n",
    "# Validation Set\n",
    "val_img_folder = 'Data/val_img'\n",
    "val_img_list = os.listdir(val_img_folder)\n",
    "for i in range(len(val_img_list)):\n",
    "    img = sitk.ReadImage(val_img_folder + '/' + val_img_list[i], imageIO=\"NrrdImageIO\")\n",
    "    curr_x = np.expand_dims(sitk.GetArrayFromImage(img), axis=0)\n",
    "    if i == 0:\n",
    "        x_val = curr_x\n",
    "    else:\n",
    "        x_val = np.concatenate((x_val, curr_x), axis=0)\n",
    "\n",
    "val_msk_folder = 'Data/val_msk'\n",
    "val_msk_list = os.listdir(val_msk_folder)\n",
    "for i in range(len(val_msk_list)):\n",
    "    seg = sitk.ReadImage(val_msk_folder + '/' + val_msk_list[i], imageIO=\"NrrdImageIO\")\n",
    "    curr_y = np.expand_dims(sitk.GetArrayFromImage(seg), axis=0)\n",
    "    if i == 0:\n",
    "        y_val = curr_y\n",
    "    else:\n",
    "        y_val = np.concatenate((y_val, curr_y), axis=0)\n",
    "\n",
    "test_img_folder = 'Data/test_img'\n",
    "test_img_list = os.listdir(test_img_folder)\n",
    "for i in range(len(test_img_list)):\n",
    "    img = sitk.ReadImage(test_img_folder + '/' + test_img_list[i], imageIO=\"NrrdImageIO\")\n",
    "    curr_x = np.expand_dims(sitk.GetArrayFromImage(img), axis=0)\n",
    "    if i == 0:\n",
    "        x_test = curr_x\n",
    "    else:\n",
    "        x_test = np.concatenate((x_test, curr_x), axis=0)\n",
    "\n",
    "# Test Set\n",
    "test_msk_folder = 'Data/test_msk'\n",
    "test_msk_list = os.listdir(test_msk_folder)\n",
    "for i in range(len(test_msk_list)):\n",
    "    seg = sitk.ReadImage(test_msk_folder + '/' + test_msk_list[i], imageIO=\"NrrdImageIO\")\n",
    "    curr_y = np.expand_dims(sitk.GetArrayFromImage(seg), axis=0)\n",
    "    if i == 0:\n",
    "        y_test = curr_y\n",
    "    else:\n",
    "        y_test = np.concatenate((y_test, curr_y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dataset compatible with the model\n",
    "x_train = np.transpose(x_train, (0, 2, 3, 1)).astype('float')\n",
    "y_train = np.transpose(y_train, (0, 2, 3, 1)).astype('float')\n",
    "x_val = np.transpose(x_val, (0, 2, 3, 1)).astype('float')\n",
    "y_val = np.transpose(y_val, (0, 2, 3, 1)).astype('float')\n",
    "x_test = np.transpose(x_test, (0, 2, 3, 1)).astype('float')\n",
    "y_test = np.transpose(y_test, (0, 2, 3, 1)).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Model\n",
    "my_model = vnet(loss=dice_loss) # Using different loss function by changing this line\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "history = my_model.fit(x=x_train, y=y_train, validation_data=(x_val, y_val), batch_size=1, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model after training\n",
    "my_model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using test set to evaluate the trained model\n",
    "my_model.evaluate(x=x_test, y=y_test, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting history of loss function\n",
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting history of metric\n",
    "plt.plot(history.history['iou_score'],color='b')\n",
    "plt.plot(history.history['val_iou_score'],color='k')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('IoU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
